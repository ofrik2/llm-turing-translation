# Round-trip Translation Turing Machine with LLM Agents

## 1. Overview

This project implements a simple "Turing-machine-like" system composed of three LLM-based agents, connected via files, using a CLI interface to a language model (e.g., Claude CLI).

Each agent performs one translation step:

1. English → Spanish  
2. Spanish → Hebrew  
3. Hebrew → English  

We start from an English sentence with a controlled amount of typos, pass it through the three agents, and then compare the **semantic distance** between:

- the original English sentence, and  
- the final English sentence after the full round-trip.

Semantic distance is measured using vector embeddings and cosine distance.  
By repeating this process for different typo percentages, we obtain an empirical relationship between **typo rate** and **semantic drift**.

---

## 2. Conceptual Architecture

### 2.1 What is an "agent"?

In this project, an **agent** is a small, stateless program that:

- takes text as input (from a file),
- performs a transformation (translation),
- writes text as output (to a file),
- has no memory of previous calls,
- and only communicates through files.

This is analogous to a **Turing Machine**, where:

- the "tape" = our files on disk,  
- each agent = one simple state/transition,
- the whole system = a pipeline of simple steps.

### 2.2 Data flow

For a given typo level X (e.g., 0, 20, 40):

1. `data/en_input_X.txt` — original English (with X% typos)
2. `agents/en2es.sh` → `data/es_X.txt` — English → Spanish
3. `agents/es2he.sh` → `data/he_X.txt` — Spanish → Hebrew
4. `agents/he2en.sh` → `data/en_back_X.txt` — Hebrew → English

We then compare:

- `en_input_X.txt` (original noisy English), and  
- `en_back_X.txt` (round-trip English),

using embeddings.

---

## 3. Project Structure

```text
llm-turing-translation/
  .gitignore               # ignore Python caches, venvs, etc.
  README.md                # this documentation
  requirements.txt         # Python dependencies for embeddings/plotting
  run_pipeline.sh          # orchestrates the three translation agents
  agents/
    en2es.sh               # English → Spanish agent (skill)
    es2he.sh               # Spanish → Hebrew agent (skill)
    he2en.sh               # Hebrew → English agent (skill)
  data/
    en_input_0.txt         # English sentence, 0% typos
    en_input_20.txt        # English sentence, ~20% typos
    en_input_40.txt        # English sentence, ~40% typos
                           # (other files here are generated by the pipeline)
  embeddings/
    compute_distances.py   # embeddings + cosine distance + plot
  experiments/
    .gitkeep               # placeholder so the folder exists in git
                           # (results CSV and PNG will go here)
